{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10751668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\aywski\\appdata\\roaming\\python\\python312\\site-packages (1.4.1.post1)\n",
      "Collecting sklearn_crfsuite\n",
      "  Downloading sklearn_crfsuite-0.3.6-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.19.5 in c:\\users\\aywski\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\aywski\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (1.12.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\aywski\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\aywski\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (3.4.0)\n",
      "Collecting python-crfsuite>=0.8.3 (from sklearn_crfsuite)\n",
      "  Downloading python_crfsuite-0.9.10-cp312-cp312-win_amd64.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: six in c:\\users\\aywski\\appdata\\roaming\\python\\python312\\site-packages (from sklearn_crfsuite) (1.16.0)\n",
      "Collecting tabulate (from sklearn_crfsuite)\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Requirement already satisfied: tqdm>=2.0 in c:\\users\\aywski\\appdata\\roaming\\python\\python312\\site-packages (from sklearn_crfsuite) (4.66.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\aywski\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=2.0->sklearn_crfsuite) (0.4.6)\n",
      "Downloading sklearn_crfsuite-0.3.6-py2.py3-none-any.whl (12 kB)\n",
      "Downloading python_crfsuite-0.9.10-cp312-cp312-win_amd64.whl (154 kB)\n",
      "   ---------------------------------------- 0.0/154.7 kB ? eta -:--:--\n",
      "   ------------- -------------------------- 51.2/154.7 kB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 154.7/154.7 kB 2.3 MB/s eta 0:00:00\n",
      "Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Installing collected packages: python-crfsuite, tabulate, sklearn_crfsuite\n",
      "Successfully installed python-crfsuite-0.9.10 sklearn_crfsuite-0.3.6 tabulate-0.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn sklearn_crfsuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f8da834512781a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T18:23:23.480252Z",
     "start_time": "2024-03-21T18:23:23.472952Z"
    }
   },
   "outputs": [],
   "source": [
    "def transform_dataset(page_dataset, for_inference):\n",
    "    labeled_text_dataset = []\n",
    "    for page in page_dataset:\n",
    "        task_id = page[\"taskId\"]\n",
    "        page_words = page[\"representativeData\"][\"page_data_words\"]\n",
    "        \n",
    "        geo_dictionary = {}\n",
    "        if not for_inference:\n",
    "            page_answers = page.get(\"answers\")\n",
    "            for page_answer in page_answers[0][\"answer\"]:\n",
    "                geo_label = page_answer[\"id\"]\n",
    "                for geo_part in page_answer[\"data\"]:\n",
    "                    for index in range(geo_part[\"start\"], geo_part[\"end\"]):\n",
    "                        geo_dictionary[index] = geo_label\n",
    "        \n",
    "        labeled_text = []\n",
    "        for word_index, word in enumerate(page_words):\n",
    "            word_label = \"0\" if for_inference else geo_dictionary.get(word_index, \"O\")\n",
    "            labeled_text.append((word, word_label))\n",
    "            \n",
    "        labeled_text_dataset.append((task_id, labeled_text))\n",
    "    \n",
    "    return labeled_text_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e790d71857b5686",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T18:23:23.489442Z",
     "start_time": "2024-03-21T18:23:23.482152Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def get_labeled_dataset(dataset_path, for_inference=False):\n",
    "    with open(dataset_path, encoding=\"utf-8\") as json_dataset:\n",
    "        dataset = json.load(json_dataset)\n",
    "        \n",
    "    labeled_dataset = transform_dataset(dataset[\"data\"][\"results\"], for_inference)\n",
    "    return labeled_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d1eea18c02ae465",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T18:23:23.499428Z",
     "start_time": "2024-03-21T18:23:23.492046Z"
    }
   },
   "outputs": [],
   "source": [
    "def word2features(text, i):\n",
    "    word = text[i][0]\n",
    "    \n",
    "    features = {\n",
    "        \"word.lower()\": word.lower(),\n",
    "        \"word[-2:]\": word[-2:],\n",
    "        \"word[-3:]\": word[-3:],\n",
    "        \"word[:2]\": word[:2],\n",
    "        \"word[:3]\": word[:3],\n",
    "        \"word.isupper()\": word.isupper(),\n",
    "        \"word.istitle()\": word.istitle(),\n",
    "        \"word.isdigit()\": word.isdigit(),\n",
    "        \"word.endswithdot\": word.endswith(\".\")\n",
    "    }\n",
    "    \n",
    "    for offset in [-3, -2, -1, 1, 2, 3]:\n",
    "        if 0 <= i + offset < len(text):\n",
    "            neighbor_word = text[i + offset][0]\n",
    "            features.update({\n",
    "                f\"{offset}:word.lower()\": neighbor_word.lower(),\n",
    "                f\"{offset}:word.istitle()\": neighbor_word.istitle(),\n",
    "                f\"{offset}:word.isupper()\": neighbor_word.isupper(),\n",
    "                f\"{offset}:word.endswithdot\": neighbor_word.endswith(\".\")\n",
    "            })\n",
    "        else:\n",
    "            features[f\"offset_{offset}_limit\"] = True\n",
    "        \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ff429aa50eeeaeb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T18:23:23.509365Z",
     "start_time": "2024-03-21T18:23:23.500903Z"
    }
   },
   "outputs": [],
   "source": [
    "def text2features(text):\n",
    "    return [word2features(text, index) for index in range(len(text))]\n",
    "\n",
    "def text2labels(text):\n",
    "    return [label for _, label in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50d63d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_validation_result(X_validation, y_pred):\n",
    "    validation_result = []\n",
    "    \n",
    "    for ((task_id, _), predictions) in zip(X_validation, y_pred):\n",
    "        answers = {}\n",
    "        current_label = None\n",
    "        start_index = None\n",
    "        \n",
    "        for current_index, label in enumerate(predictions):\n",
    "            if label == current_label:\n",
    "                continue\n",
    "            else:\n",
    "                if current_label is not None and current_label != \"O\":\n",
    "                    if current_label not in answers:\n",
    "                        answers[current_label] = []\n",
    "                    answers[current_label].append({\"start\": start_index, \"end\": current_index})\n",
    "                \n",
    "                if label != \"0\":\n",
    "                    current_label = label\n",
    "                    start_index = current_index\n",
    "                else:\n",
    "                    current_label = None\n",
    "    \n",
    "        if current_label is not None and current_label != \"O\":\n",
    "            if current_label not in answers:\n",
    "                answers[current_label] = []\n",
    "            answers[current_label].append({\"start\": start_index, \"end\": len(predictions)})\n",
    "        \n",
    "        validation_answers = []\n",
    "        for label, segments in answers.items():\n",
    "            validation_answers.append({\"id\": label, \"data\": segments})\n",
    "        \n",
    "        validation_result.append({\n",
    "            \"taskId\": task_id,\n",
    "            \"answer\": validation_answers\n",
    "        })\n",
    "        \n",
    "    return validation_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14f25440dc7c22ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T18:23:24.634739Z",
     "start_time": "2024-03-21T18:23:23.511075Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = get_labeled_dataset(\"../jsons/train_geo_extractor.json\")\n",
    "\n",
    "X_train = [text2features(text) for _, text in train_dataset]\n",
    "y_train = [text2labels(text) for _, text in train_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73a3766c5aeb1fc6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T18:23:53.208689Z",
     "start_time": "2024-03-21T18:23:24.636245Z"
    }
   },
   "outputs": [],
   "source": [
    "import sklearn_crfsuite\n",
    "\n",
    "crf_model = sklearn_crfsuite.CRF(\n",
    "    algorithm='ap',\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=False\n",
    ")\n",
    "\n",
    "try:\n",
    "    crf_model.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7076bb8edeacf502",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T18:23:53.511363Z",
     "start_time": "2024-03-21T18:23:53.211534Z"
    }
   },
   "outputs": [],
   "source": [
    "test_dataset = get_labeled_dataset(\"../jsons/test_geo_extractor.json\")\n",
    "\n",
    "X_test = [text2features(text) for _, text in test_dataset]\n",
    "y_test = [text2labels(text) for _, text in test_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad83f81a209701d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T18:23:54.186254Z",
     "start_time": "2024-03-21T18:23:53.513891Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "                O       0.99      0.99      0.99     62822\n",
      "     central_city       0.44      0.36      0.40       184\n",
      "      geo_address       0.89      0.75      0.82      1040\n",
      "     geo_building       0.83      0.74      0.78       453\n",
      "         geo_city       0.84      0.84      0.84      1433\n",
      "     geo_district       0.87      0.78      0.82       387\n",
      "geo_microdistrict       0.60      0.53      0.56       382\n",
      "       geo_region       0.99      0.99      0.99      1733\n",
      "geo_region_oblast       0.86      0.87      0.86       297\n",
      "       geo_street       0.81      0.79      0.80      1059\n",
      "\n",
      "         accuracy                           0.98     69790\n",
      "        macro avg       0.81      0.76      0.79     69790\n",
      "     weighted avg       0.98      0.98      0.98     69790\n",
      "\n",
      "Matthews Correlation Coefficient: 0.8746781148689454\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, matthews_corrcoef\n",
    "\n",
    "y_pred = crf_model.predict(X_test)\n",
    "y_test_flat = [label for text in y_test for label in text]\n",
    "y_pred_flat = [label for text in y_pred for label in text]\n",
    "\n",
    "report = classification_report(y_test_flat, y_pred_flat)\n",
    "matthews_correlation_coefficient = matthews_corrcoef(y_test_flat, y_pred_flat)\n",
    "\n",
    "print(report)\n",
    "print(f\"Matthews Correlation Coefficient: {matthews_correlation_coefficient}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b558eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dataset = get_labeled_dataset(\"../jsons/val_no_answer_geo_extractor.json\", for_inference=True)\n",
    "\n",
    "X_validation = [(task_id, text2features(text)) for task_id, text in validation_dataset]\n",
    "\n",
    "X_validation_features = [text_features for _, text_features in X_validation]\n",
    "\n",
    "y_pred = crf_model.predict(X_validation_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b5b2011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation result has been saved!\n"
     ]
    }
   ],
   "source": [
    "validation_result = get_validation_result(X_validation, y_pred)\n",
    "\n",
    "with open(\"myres.json\", \"w\", encoding=\"utf-8\") as file:\n",
    "    json.dump(validation_result, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"Validation result has been saved!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
